# Iterables vs Iteradores en Python ‚Äì Backend Profesional

## 1. Concepto clave

- **Iterable:** objeto que puede ser recorrido en un bucle `for`.  
  Ejemplos: list, tuple, dict, set, str.  
  - Tiene el m√©todo `__iter__()`.
  - Cada llamada a `iter()` devuelve un **iterador**.

- **Iterador:** objeto que produce elementos uno a uno bajo demanda.  
  - Tiene los m√©todos `__iter__()` y `__next__()`.
  - Se usa para **procesar grandes vol√∫menes de datos sin cargarlos todos en memoria**.

---

## 2. Diferencia pr√°ctica

```python
# Iterable
mi_lista = [1, 2, 3, 4]
for elemento in mi_lista:
    print(elemento)

# Iterador
mi_iterador = iter(mi_lista)
print(next(mi_iterador))  # 1
print(next(mi_iterador))  # 2
Cada iterable puede generar m√∫ltiples iteradores independientes.

Los iteradores consumen sus elementos: una vez recorridos, no se pueden reutilizar sin crear uno nuevo.

3. Uso profesional en backend
Evitar cargar grandes datasets completos en memoria.

Procesar logs o streams l√≠nea por l√≠nea.

python
Copiar c√≥digo
def leer_archivo_grande(ruta):
    with open(ruta, "r", encoding="utf-8") as f:
        for linea in f:  # f es iterable, produce iterador internamente
            yield linea.strip()  # Generador = iterador bajo demanda
yield transforma la funci√≥n en un generador, que es un iterador eficiente.

4. Iteradores vs listas: eficiencia
python
Copiar c√≥digo
# Lista completa (carga toda en memoria)
numeros = [x**2 for x in range(10_000_000)]

# Iterador con generador (lazy evaluation)
numeros_iter = (x**2 for x in range(10_000_000))

# Solo se calculan los valores cuando se necesitan
‚úîÔ∏è Generadores = bajo consumo de memoria, ideales para pipelines de datos y streams.

5. Comportamiento en bucles
python
Copiar c√≥digo
mi_iter = iter([1,2,3])
for x in mi_iter:
    print(x)  # 1,2,3

for x in mi_iter:
    print(x)  # No imprime nada, el iterador ya se consumi√≥
Los iteradores no son reiniciables.

Para reiniciar, crear un nuevo iterador desde el iterable.

6. Errores comunes de juniors
‚ùå Intentar iterar varias veces sobre un iterador sin recrearlo

‚ùå Cargar datasets enormes en listas innecesariamente

‚ùå Confundir iterable con iterador

‚ùå No usar yield para procesamiento lazy ‚Üí alto consumo de memoria

7. Buenas pr√°cticas profesionales
Usar iterables cuando necesitas m√∫ltiples pasadas sobre los datos.

Usar iteradores/generadores para procesamiento bajo demanda y streaming.

Evitar cargar toda la data en memoria si no es necesario.

Documentar cu√°ndo un objeto es iterable y cu√°ndo iterador.

Aprovechar enumerate(), zip(), map() y filter() para loops limpios y eficientes.

8. Checklist mental backend
‚úîÔ∏è Iterable o iterador correctamente usado?

‚úîÔ∏è Procesamiento lazy cuando es necesario?

‚úîÔ∏è Memoria optimizada en datasets grandes?

‚úîÔ∏è C√≥digo limpio y profesional para loops?

9. Regla de oro
En backend y pipelines, procesa los datos bajo demanda siempre que sea posible.
Los iteradores y generadores son la clave para eficiencia y escalabilidad profesional.

yaml
Copiar c√≥digo

---

üî• **Verdad profesional**  
El 60% de problemas de memoria en pipelines de datos provienen de **usar listas completas en lugar de iteradores/generadores**.